{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9c1a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm \n",
    "from colorama import Style,Fore\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import time\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8727f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openJson(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def saveJson(path,data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "       json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "       print(Style.BRIGHT+Fore.GREEN+'\\n json saved'+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "channelsF2 = openJson(\"../jsons/channelsF2.json\")\n",
    "len(channelsF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f475b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plages = {\n",
    "    '0-10': 0,\n",
    "    '10-50': 0,\n",
    "    '50-100': 0,\n",
    "    '>100': 0\n",
    "}\n",
    "\n",
    "for item in channelsF2:\n",
    "    bio = item.get('bio', '').strip()\n",
    "    nb_mots = len(bio.split())\n",
    "    \n",
    "    if nb_mots <= 10:\n",
    "        plages['0-10'] += 1\n",
    "    elif nb_mots <= 50:\n",
    "        plages['10-50'] += 1\n",
    "    elif nb_mots <= 100:\n",
    "        plages['50-100'] += 1\n",
    "    else:\n",
    "        plages['>100'] += 1\n",
    "\n",
    "labels = list(plages.keys())\n",
    "counts = list(plages.values())\n",
    "total = sum(counts)\n",
    "percentages = [count / total * 100 for count in counts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(labels, counts, color='skyblue')\n",
    "\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{pct:.1f}%', \n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xlabel('Plage de nombre de mots dans le bio')\n",
    "plt.ylabel('Nombre de chaînes')\n",
    "plt.title('Distribution des chaînes selon la longueur du bio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5051f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapetube import get_channel\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "def getContext(channel_id):\n",
    "    api_key = os.getenv(\"YOUTUBE_API_KEY2\")\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    video_ids = []\n",
    "    for video in get_channel(channel_id, limit=3, sort_by='newest', content_type='videos'):\n",
    "        video_ids.append(video['videoId'])\n",
    "\n",
    "    if not video_ids:\n",
    "        return \"No videos found.\"\n",
    "\n",
    "    request = youtube.videos().list(part='snippet', id=','.join(video_ids))\n",
    "    response = request.execute()\n",
    "\n",
    "    combined = \"\"\n",
    "    for item in response['items']:\n",
    "        title = item['snippet'].get('title', 'No title')\n",
    "        description = item['snippet'].get('description', 'No description')\n",
    "        tags = ', '.join(item['snippet'].get('tags', [])) if 'tags' in item['snippet'] else 'No tags'\n",
    "\n",
    "        combined += f\"Title: {title}\\nDescription: {description}\\nTags: {tags}\\n\\n\"\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e94bff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 1299/1836 [04:49<01:33,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 1400/1836 [05:08<01:50,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1500/1836 [05:28<00:55,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 1598/1836 [05:51<00:46,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1700/1836 [06:12<00:33,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1800/1836 [06:33<00:07,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1836/1836 [06:39<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m\n",
      " json saved\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "temp = 0\n",
    "for item in tqdm(channelsF2):\n",
    "    bio = item.get('bio', '').strip()\n",
    "    nb_mots = len(bio.split())\n",
    "    \n",
    "    if nb_mots <= 100 :\n",
    "        context = getContext(item['id_chaine'])\n",
    "        item['context'] = context\n",
    "        \n",
    "    temp+=1\n",
    "    if temp >= 100:\n",
    "        saveJson(\"../jsons/channelsF2.json\",channelsF2)\n",
    "        temp = 0\n",
    "   \n",
    "saveJson(\"../jsons/channelsF2.json\",channelsF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d5611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d50fdc1",
   "metadata": {},
   "source": [
    "# 1.Echantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949facc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "echantillon = random.sample(channelsF2, 200)\n",
    "\n",
    "for item in echantillon:\n",
    "    item['link']=f\"https://www.youtube.com/channel/{item['id_chaine']}\"\n",
    "    item['pertinente']=\"\"\n",
    "    \n",
    "saveJson(\"../jsons/echantillon.json\",echantillon)\n",
    "print(len(echantillon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c1168",
   "metadata": {},
   "source": [
    "# 2.Manuel Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "echantillon = openJson(\"../jsons/echantillon.json\")\n",
    "len(echantillon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "valeurs = [item.get(\"pertinente\") for item in echantillon]\n",
    "compteur = Counter(valeurs)\n",
    "\n",
    "for valeur, nb in compteur.items():\n",
    "    print(f\"{valeur} → {nb} chaines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512537a2",
   "metadata": {},
   "source": [
    "# 3.With LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31960427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "297579f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_flash_1 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_1\"))\n",
    "gemini_flash_2 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_2\"))\n",
    "gemini_flash_3 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysprompt = \"\"\"\n",
    "# La définition d’autosuffisance\n",
    "\n",
    "L'autosuffisance est la démarche visant à acquérir la capacité de subvenir par soi-même à ses besoins fondamentaux, \n",
    "en premier lieu alimentaires par l'autoconsommation – c'est-à-dire produire, récolter et conserver un maximum de sa propre nourriture, \n",
    "souvent en privilégiant le bio, le local et le saisonnier. \n",
    "\n",
    "L'autosuffisance Plus qu'une simple recherche d'autonomie matérielle, elle représente un engagement pour être moins dépendant du système économique et social extérieur, impliquant des choix concrets comme trouver un lieu propice et le concevoir judicieusement (par exemple en permaculture), \n",
    "ainsi qu'un changement dans la manière de valoriser son temps et de consommer, formant ainsi le fondement d'une vie plus autonome.\n",
    "\n",
    "---\n",
    "\n",
    "# Votre mission\n",
    "\n",
    "- Décider si une chaine concerne la thématique de l'autosuffisance en se basant sur ses métadonnées (Nom chaine, Bio).\n",
    "  \n",
    "- Les chaînes des autosuffisants ou qui partagent de contenu sur l’autosuffisance sont pertinentes.\n",
    "\n",
    "- Attribuer un score entier de 1 à 10 pour évaluer la pertinence de la chaine par rapport à la thématique de l'autosuffisance.\n",
    "\n",
    "---\n",
    "\n",
    "# Votre réponse  \n",
    "\n",
    "- La réponse doit être au format JSON :  \n",
    "  \n",
    "    \"decision\": \"oui ou non\",\n",
    "    \"justification\": \"Justifiez votre décision avec des arguments\"\n",
    "    \"score\": votre èvaluation\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "userprompt = \"\"\"\n",
    "Nom de la chaine\n",
    "---\n",
    "{nom_chaine}\n",
    "\n",
    "Bio\n",
    "---\n",
    "{bio}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", sysprompt),\n",
    "    (\"user\", userprompt)\n",
    "])\n",
    "\n",
    "chain_1 = prompt | gemini_flash_1\n",
    "chain_2 = prompt | gemini_flash_2\n",
    "chain_3 = prompt | gemini_flash_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570f8f9",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c1e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = {\n",
    "    \"nom_chaine\": \"L’Ôton’home\",\n",
    "      \"bio\": \"Nous sommes un couple parent de 2 jeunes garçons et avons acheté à l’été 2020 une GRANDE GRANGE sur un peu plus de 3 hectares de terrain dans le Tarn. Notre objectif: transformer cette grange en HABITATION la plus AUTONOME possible, ce par nos propres moyens, et en faire notre petit paradis. Venez partager notre aventure et suivre ce projet un peu fou ici.\\n\\nLe but de notre chaîne: montrer toutes les étapes de la TRANSFORMATION de la GRANGE en HABITATION, échanger sur l’AUTONOMIE, partager nos DIY en matière de PRODUITS MÉNAGERS et COSMÉTIQUES, toujours dans une optique d’AUTONOMIE.\\n\\nPrécision importante: nous ne sommes PAS des professionnels du bâtiment donc nos vidéos n'ont pas valeur de tutoriels mais de simples partages d'expérience.\\n\\nN’hésitez pas à laisser vos commentaires et à vous abonner à la chaîne. Vous pouvez également nous retrouver sur Facebook et Tipeee. En espérant pouvoir vous inspirer.\\n\\nDes bises,\\n\\nAurélie & David\",\n",
    "       }\n",
    "print(input)\n",
    "print(chain_1.invoke(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339e61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8628121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
