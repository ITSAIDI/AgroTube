{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9c1a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from tqdm import tqdm \n",
    "from colorama import Style,Fore\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import time\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8727f8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def openJson(path):\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def saveJson(path,data):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "       json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "       print(Style.BRIGHT+Fore.GREEN+'\\n json saved'+Style.RESET_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2c29a7",
   "metadata": {},
   "source": [
    "# Short Bio probleme resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f4b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "channelsF2 = openJson(\"../jsons/channelsF2.json\")\n",
    "len(channelsF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f475b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plages = {\n",
    "    '0-10': 0,\n",
    "    '10-50': 0,\n",
    "    '50-100': 0,\n",
    "    '>100': 0\n",
    "}\n",
    "\n",
    "for item in channelsF2:\n",
    "    bio = item.get('bio', '').strip()\n",
    "    nb_mots = len(bio.split())\n",
    "    \n",
    "    if nb_mots <= 10:\n",
    "        plages['0-10'] += 1\n",
    "    elif nb_mots <= 50:\n",
    "        plages['10-50'] += 1\n",
    "    elif nb_mots <= 100:\n",
    "        plages['50-100'] += 1\n",
    "    else:\n",
    "        plages['>100'] += 1\n",
    "\n",
    "labels = list(plages.keys())\n",
    "counts = list(plages.values())\n",
    "total = sum(counts)\n",
    "percentages = [count / total * 100 for count in counts]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "bars = ax.bar(labels, counts, color='skyblue')\n",
    "\n",
    "for bar, pct in zip(bars, percentages):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{pct:.1f}%', \n",
    "            ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.xlabel('Plage de nombre de mots dans le bio')\n",
    "plt.ylabel('Nombre de chaînes')\n",
    "plt.title('Distribution des chaînes selon la longueur du bio')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5051f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapetube import get_channel\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "def getContext(channel_id):\n",
    "    api_key = os.getenv(\"YOUTUBE_API_KEY2\")\n",
    "    youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "    video_ids = []\n",
    "    for video in get_channel(channel_id, limit=3, sort_by='newest', content_type='videos'):\n",
    "        video_ids.append(video['videoId'])\n",
    "\n",
    "    if not video_ids:\n",
    "        return \"No videos found.\"\n",
    "\n",
    "    request = youtube.videos().list(part='snippet', id=','.join(video_ids))\n",
    "    response = request.execute()\n",
    "\n",
    "    combined = \"\"\n",
    "    for item in response['items']:\n",
    "        title = item['snippet'].get('title', 'No title')\n",
    "        description = item['snippet'].get('description', 'No description')\n",
    "        tags = ', '.join(item['snippet'].get('tags', [])) if 'tags' in item['snippet'] else 'No tags'\n",
    "\n",
    "        combined += f\"Title: {title}\\nDescription: {description}\\nTags: {tags}\\n\\n\"\n",
    "\n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e94bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 0\n",
    "for item in tqdm(channelsF2):\n",
    "    bio = item.get('bio', '').strip()\n",
    "    nb_mots = len(bio.split())\n",
    "    \n",
    "    if nb_mots <= 100 :\n",
    "        context = getContext(item['id_chaine'])\n",
    "        item['context'] = context\n",
    "        \n",
    "    temp+=1\n",
    "    if temp >= 100:\n",
    "        saveJson(\"../jsons/channelsF2.json\",channelsF2)\n",
    "        temp = 0\n",
    "   \n",
    "saveJson(\"../jsons/channelsF2.json\",channelsF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097d5611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d50fdc1",
   "metadata": {},
   "source": [
    "# 1.Echantillon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949facc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "echantillon = random.sample(channelsF2, 200)\n",
    "\n",
    "for item in echantillon:\n",
    "    item['link']=f\"https://www.youtube.com/channel/{item['id_chaine']}\"\n",
    "    item['pertinente']=\"\"\n",
    "    \n",
    "saveJson(\"../jsons/echantillon.json\",echantillon)\n",
    "print(len(echantillon))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7c1168",
   "metadata": {},
   "source": [
    "# 2.Manuel Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a8395",
   "metadata": {},
   "outputs": [],
   "source": [
    "echantillon = openJson(\"../jsons/echantillon.json\")\n",
    "len(echantillon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a0bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "valeurs = [item.get(\"pertinente\") for item in echantillon]\n",
    "compteur = Counter(valeurs)\n",
    "\n",
    "for valeur, nb in compteur.items():\n",
    "    print(f\"{valeur} → {nb} chaines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512537a2",
   "metadata": {},
   "source": [
    "# 3.With LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31960427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "297579f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_flash_1 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_1\"))\n",
    "gemini_flash_2 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_2\"))\n",
    "gemini_flash_3 = GoogleGenerativeAI(model=\"gemini-2.0-flash\", google_api_key=os.getenv(\"GOOGLE_API_KEY_3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sysprompt = \"\"\"\n",
    "# La définition d’autosuffisance\n",
    "\n",
    "L'autosuffisance est la démarche visant à acquérir la capacité de subvenir par soi-même à ses besoins fondamentaux, \n",
    "en premier lieu alimentaires par l'autoconsommation – c'est-à-dire produire, récolter et conserver un maximum de sa propre nourriture, \n",
    "souvent en privilégiant le bio, le local et le saisonnier. \n",
    "\n",
    "L'autosuffisance Plus qu'une simple recherche d'autonomie matérielle, elle représente un engagement pour être moins dépendant du système économique et social extérieur, impliquant des choix concrets comme trouver un lieu propice et le concevoir judicieusement (par exemple en permaculture), \n",
    "ainsi qu'un changement dans la manière de valoriser son temps et de consommer, formant ainsi le fondement d'une vie plus autonome.\n",
    "\n",
    "---\n",
    "\n",
    "# Votre mission\n",
    "\n",
    "- Décider si une chaîne concerne la thématique de l’autosuffisance en se basant sur un contexte qui est soit :\n",
    "\n",
    "   context = bio + nom de la chaîne\n",
    "\n",
    " ou\n",
    "\n",
    "   context = nom de la chaîne + titres, descriptions, tags des trois dernières vidéos de la chaîne (pour les chaînes dont le bio est très court ou vide)\n",
    "\n",
    "- Les chaînes des autosuffisants ou qui partagent de contenu sur l’autosuffisance sont pertinentes.\n",
    "\n",
    "- Attribuer un score entier de 1 à 10 pour évaluer la pertinence de la chaine par rapport à la thématique de l'autosuffisance.\n",
    "\n",
    "---\n",
    "\n",
    "# Votre réponse  \n",
    "\n",
    "- La réponse doit être au format JSON :  \n",
    "  \n",
    "    \"decision\": \"oui ou non\",\n",
    "    \"justification\": \"Justifiez votre décision avec des arguments\"\n",
    "    \"score\": votre èvaluation\n",
    " \n",
    "\"\"\"\n",
    "\n",
    "userprompt = \"\"\"\n",
    "Le context ici\n",
    "---\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", sysprompt),\n",
    "    (\"user\", userprompt)\n",
    "])\n",
    "\n",
    "chain_1 = prompt | gemini_flash_1\n",
    "chain_2 = prompt | gemini_flash_2\n",
    "chain_3 = prompt | gemini_flash_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d570f8f9",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7c1e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context': '\\n            \"L’Ôton’home\",\\n    \"Nous sommes un couple parent de 2 jeunes garçons et avons acheté à l’été 2020 une GRANDE GRANGE sur un peu plus de 3 hectares de terrain dans le Tarn. Notre objectif: transformer cette grange en HABITATION la plus AUTONOME possible, ce par nos propres moyens, et en faire notre petit paradis. Venez partager notre aventure et suivre ce projet un peu fou ici.\\n\\nLe but de notre chaîne: montrer toutes les étapes de la TRANSFORMATION de la GRANGE en HABITATION, échanger sur l’AUTONOMIE, partager nos DIY en matière de PRODUITS MÉNAGERS et COSMÉTIQUES, toujours dans une optique d’AUTONOMIE.\\n\\nPrécision importante: nous ne sommes PAS des professionnels du bâtiment donc nos vidéos n\\'ont pas valeur de tutoriels mais de simples partages d\\'expérience.\\n\\nN’hésitez pas à laisser vos commentaires et à vous abonner à la chaîne. Vous pouvez également nous retrouver sur Facebook et Tipeee. En espérant pouvoir vous inspirer.\\n\\nDes bises,\\n\\nAurélie & David\",\\n    '}\n",
      "```json\n",
      "{\n",
      "\"decision\": \"oui\",\n",
      "\"justification\": \"La chaîne \\\"L’Ôton’home\\\" décrit clairement un projet de transformation d'une grange en habitation autonome, avec un focus sur l'autonomie, les DIY pour les produits ménagers et cosmétiques. Le couple souhaite partager leur aventure et leur expérience dans ce domaine, ce qui correspond à la thématique de l'autosuffisance.\",\n",
      "\"score\": 9\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "         \"context\":\"\"\"\n",
    "            \"L’Ôton’home\",\n",
    "    \"Nous sommes un couple parent de 2 jeunes garçons et avons acheté à l’été 2020 une GRANDE GRANGE sur un peu plus de 3 hectares de terrain dans le Tarn. Notre objectif: transformer cette grange en HABITATION la plus AUTONOME possible, ce par nos propres moyens, et en faire notre petit paradis. Venez partager notre aventure et suivre ce projet un peu fou ici.\\n\\nLe but de notre chaîne: montrer toutes les étapes de la TRANSFORMATION de la GRANGE en HABITATION, échanger sur l’AUTONOMIE, partager nos DIY en matière de PRODUITS MÉNAGERS et COSMÉTIQUES, toujours dans une optique d’AUTONOMIE.\\n\\nPrécision importante: nous ne sommes PAS des professionnels du bâtiment donc nos vidéos n'ont pas valeur de tutoriels mais de simples partages d'expérience.\\n\\nN’hésitez pas à laisser vos commentaires et à vous abonner à la chaîne. Vous pouvez également nous retrouver sur Facebook et Tipeee. En espérant pouvoir vous inspirer.\\n\\nDes bises,\\n\\nAurélie & David\",\n",
    "    \"\"\"\n",
    "\n",
    "} \n",
    "print(input)\n",
    "print(chain_1.invoke(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14257a7d",
   "metadata": {},
   "source": [
    "## Run on the samples "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a1897",
   "metadata": {},
   "source": [
    "### prepare the LLM input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d29b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "echantillon = openJson(\"../jsons/echantillon.json\")\n",
    "channelsF2  = openJson(\"../jsons/channelsF2.json\")\n",
    "len(channelsF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "echantillonPredictions= []\n",
    "\n",
    "for item in echantillon:\n",
    "    llmInput = \"\"\n",
    "    for channel in channelsF2:\n",
    "        if  item['id_chaine']==channel['id_chaine']:\n",
    "            if \"context\" in channel:\n",
    "              llmInput = f\"\"\"\n",
    "                              Nom Chaine :\n",
    "                              ---\n",
    "                              {channel['nom_chaine']}\n",
    "                              \n",
    "                              Bio Chaine :\n",
    "                              ---\n",
    "                              {channel['bio']}\n",
    "                              \n",
    "                              contexte d’après les vidéos :\n",
    "                              ---\n",
    "                              {channel['context']}   \n",
    "                          \"\"\"          \n",
    "            else :\n",
    "                 llmInput = f\"\"\"\n",
    "                              Nom Chaine :\n",
    "                              ---\n",
    "                              {channel['nom_chaine']}\n",
    "                              \n",
    "                              Bio Chaine :\n",
    "                              ---\n",
    "                              {channel['bio']} \n",
    "                            \"\"\"\n",
    "            break\n",
    "    echantillonPredictions.append({\n",
    "      'id_chaine':item['id_chaine'],\n",
    "      'llmInput':llmInput\n",
    "    })      \n",
    "\n",
    "saveJson(\"../jsons/echantillonPredictions.json\",echantillonPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0f39cc",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3b3087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "echantillonPredictions = openJson(\"../jsons/echantillonPredictions.json\")\n",
    "len(echantillonPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b5460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanAnswer(answer):\n",
    "    answer = answer.strip(\"`\")   \n",
    "    if answer.startswith(\"json\"):\n",
    "        answer = answer[4:].strip() \n",
    "    return  answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "temp = 0\n",
    "\n",
    "for item in tqdm(echantillonPredictions):\n",
    "  \n",
    "    input = {\"context\":item[\"llmInput\"]}\n",
    "    try:\n",
    "        if count1  <= 13:\n",
    "            #print(\"KEY 1\")\n",
    "        \n",
    "            answer = cleanAnswer(chain_1.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count1+=1\n",
    "            temp+=1            \n",
    "            \n",
    "            #print(\"count1 \",count1)  \n",
    "            \n",
    "        if count1  > 13 and count2 <= 13:\n",
    "            #print(\"KEY 2\")\n",
    "            \n",
    "            answer = cleanAnswer(chain_2.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count2+=1\n",
    "            temp+=1\n",
    "            #print(\"count2 \",count2) \n",
    "            \n",
    "        if  count1  > 13 and count2  > 13 and count3 <= 13:\n",
    "            \n",
    "            #print(\"KEY 3\")\n",
    "            \n",
    "            answer = cleanAnswer(chain_3.invoke(input))\n",
    "            answer = json.loads(answer)\n",
    "            #print(video['id_video'],'/n',answer)\n",
    "            item.update(answer)\n",
    "            \n",
    "            count3+=1\n",
    "            temp+=1\n",
    "            #print(\"count3 \",count3) \n",
    "                \n",
    "        if count1 > 13 and count2 > 13 and count3 > 13 :\n",
    "            print(\"sleep for 50 s\")\n",
    "            time.sleep(50)\n",
    "            count1 = 0\n",
    "            count2 = 0\n",
    "            count3 = 0\n",
    "        \n",
    "\n",
    "        if temp >= 100:\n",
    "            saveJson(\"../jsons/echantillonPredictions.json\",echantillonPredictions)\n",
    "            temp=0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"error {e}\")\n",
    "        \n",
    "saveJson(\"../jsons/echantillonPredictions.json\",echantillonPredictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aadbda",
   "metadata": {},
   "source": [
    "## Validate the approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7339e61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8628121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
